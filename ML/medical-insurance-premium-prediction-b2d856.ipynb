{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2497017,"sourceType":"datasetVersion","datasetId":1507683}],"dockerImageVersionId":30673,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-26T05:09:42.034476Z","iopub.execute_input":"2024-05-26T05:09:42.034896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's import \nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# what to do\n\n**A medical insurance company has released data for almost 1000 customers.create a model that predict the yearly medical cover cost.**\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/medical-insurance-premium-prediction/Medicalpremium.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**so there is no null values**","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.histplot(df['Age'],kde=True)\nplt.title('histogramof PremiumPrice')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsns.pairplot(df, x_vars=['Age', 'Diabetes', 'BloodPressureProblems', 'AnyTransplants',\n       'AnyChronicDiseases', 'Height', 'Weight', 'KnownAllergies',\n       'HistoryOfCancerInFamily', 'NumberOfMajorSurgeries'], y_vars=['PremiumPrice'], kind='scatter')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"see the three column age and height, weight are more related to premiumPrice.","metadata":{}},{"cell_type":"markdown","source":"**let's calculate correlation**\n\nhow much each column correlated to the target column premiumprice\n","metadata":{}},{"cell_type":"code","source":"correlation = df.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(correlation, annot=True, cmap='PuBuGn')\nplt.title('correlation matrix')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"so the heatmap shows that age is the most correlated column to the target column.","metadata":{}},{"cell_type":"code","source":"#let's split the data into X, and y variable\nX = df.drop('PremiumPrice',axis=1)\ny = df['PremiumPrice']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train the data","metadata":{}},{"cell_type":"code","source":"#split the data into test and train\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import libraries\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Pipeline for preprocessing and model.","metadata":{}},{"cell_type":"code","source":"#create a pipeline for preprocessing and model\npipeline = Pipeline([\n    ('scaler',StandardScaler()),\n    ('model',RandomForestRegressor())\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fit the pipeline on training data\npipeline.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's predict on the data","metadata":{}},{"cell_type":"code","source":"#predict on X_test\ny_pred = pipeline.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate the model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\nmae = mean_absolute_error(y_pred, y_test)\nmse = mean_squared_error(y_pred, y_test)\nr2 = r2_score(y_test, y_pred)\nprint('Mean absolute error :',mae)\nprint('Mean squared error :',r2)\nprint('R^2 :', r2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's use the Hyperparameter Tuning to increase the model accuracy","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hyperparameter define \nparam_grid = {\n   'model__n_estimators': [50, 100, 200], \n    'model__max_depth': [None, 10, 20],  # Maximum depth of the trees\n    'model__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n    'model__min_samples_leaf': [1, 2, 4]  # Minimum number of sample\n    \n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a grid search object and pass pipeline\ngrid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\n#get the best pamameter and model\nbest_params = grid_search.best_params_\nbest_model = grid_search.best_estimator_\n\n#predict on the test data\ny_pred_2 = best_model.predict(X_test)\n\n# Evaluate the best model\nmse = mean_squared_error(y_test, y_pred_2)\nmae = mean_absolute_error(y_test, y_pred_2)\nr2 = r2_score(y_test, y_pred_2)\nprint(\"Best Model Mean Squared Error:\", mse)\nprint(\"Mean absolute error :\",mae)\nprint(\"r2 :\",r2)\nprint(\"Best Model Hyperparameters:\", best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"**overall the model perform better than the base model after hyperparameter tuning  the Mean absolute error is 1014 which is low and r^2 is around 90% so the model is performing good.**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}